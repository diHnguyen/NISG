{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only - expires 2022-12-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Gurobi.Env(Ptr{Nothing} @0x0000000039489880, false, 0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using JuMP, Gurobi, Test, Combinatorics, LightGraphs, TimerOutputs\n",
    "\n",
    "# function solveMP()\n",
    "const gurobi_env = Gurobi.Env()\n",
    "# setparams!(gurobi_env, OutputFlag = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running...\n",
      "R = 419.71219712404\n",
      "Academic license - for non-commercial use only - expires 2022-12-04\n",
      "Gurobi Optimizer version 9.1.2 build v9.1.2rc0 (win64)\n",
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 1 rows, 952 columns and 951 nonzeros\n",
      "Model fingerprint: 0xf73eeadf\n",
      "Variable types: 1 continuous, 951 integer (951 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+01]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [4e+02, 4e+02]\n",
      "  RHS range        [1e+01, 1e+01]\n",
      "Presolve time: 0.01s\n",
      "Presolved: 1 rows, 952 columns, 951 nonzeros\n",
      "Variable types: 1 continuous, 951 integer (951 binary)\n",
      "\n",
      "Root relaxation: objective -2.124885e+02, 6 iterations, 0.00 seconds\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 -212.48851    0    1          - -212.48851      -     -    2s\n",
      "H    0     0                       0.9903735 -212.48851      -     -    2s\n",
      "H    0     0                       0.9869175 -212.48851      -     -    3s\n",
      "H    0     0                       0.9867012 -212.48851      -     -    3s\n",
      "     0     0 -159.77664    0    4    0.98670 -159.77664      -     -    4s\n",
      "     0     0 -159.77664    0    4    0.98670 -159.77664      -     -    5s\n",
      "     0     0 -143.68917    0    6    0.98670 -143.68917      -     -    7s\n",
      "     0     0 -134.56301    0    9    0.98670 -134.56301      -     -    8s\n",
      "     0     0 -131.71462    0   10    0.98670 -131.71462      -     -    8s\n",
      "     0     0 -118.79395    0    8    0.98670 -118.79395      -     -    9s\n",
      "     0     0 -118.79395    0    8    0.98670 -118.79395      -     -   10s\n",
      "     0     0 -117.52747    0    9    0.98670 -117.52747      -     -   10s\n",
      "     0     0 -114.86218    0    7    0.98670 -114.86218      -     -   10s\n",
      "     0     0 -114.76628    0    7    0.98670 -114.76628      -     -   11s\n",
      "     0     0 -112.76460    0    8    0.98670 -112.76460      -     -   11s\n",
      "     0     2 -112.76460    0    8    0.98670 -112.76460      -     -   13s\n",
      "    92    51  -46.04562   14    7    0.98670  -56.01716  5777%   4.7   16s\n",
      "   312   201  -34.73424   41    4    0.98670  -56.01716  5777%   3.3   22s\n",
      "   552   380   -4.44504   68    4    0.98670  -43.95120  4554%   3.2   26s\n",
      "   698   480  -18.57818   52    9    0.98670  -43.88827  4548%   3.4   30s\n",
      "   842   606  -17.37332   69    6    0.98670  -36.76033  3826%   3.3   35s\n",
      "  1168   843     cutoff   62         0.98670  -33.71698  3517%   3.3   44s\n",
      "  1408  1028     cutoff   19         0.98670  -31.84564  3327%   3.3   52s\n",
      "  1696  1257   -0.88773   35    1    0.98670  -30.49484  3191%   3.3   61s\n",
      "  2025  1396     cutoff   33         0.98670  -28.84136  3023%   3.3   70s\n",
      "  2127  1422   -3.91644   39    1    0.98670  -28.14147  2952%   3.2   75s\n",
      "  2641  1943   -5.12286   41    -    0.98670  -26.85035  2821%   3.2   92s\n",
      "H 3094  2013                       0.9867012  -26.79764  2816%   3.3  107s\n",
      "  3098  2016  -16.77155   46    6    0.98670  -26.79764  2816%   3.3  111s\n",
      "H 3100  1916                       0.9867012  -26.79764  2816%   3.3  112s\n",
      "H 3107  1824                       0.9867012  -26.79764  2816%   3.3  119s\n",
      "H 3108  1736                       0.9867012  -26.79764  2816%   3.3  119s\n",
      "  3129  1735  -26.79764   19   10    0.98670  -26.79764  2816%   3.4  120s\n",
      "  3278  1766     cutoff   30         0.98670  -26.79764  2816%   3.4  125s\n",
      "H 3296  1673                       0.9867012  -26.79764  2816%   3.4  125s\n",
      "  3415  1695     cutoff   36         0.98670  -26.79764  2816%   3.5  133s\n",
      "  3478  1725  -11.53763   28    5    0.98670  -26.79764  2816%   3.5  135s\n",
      "  3638  1770  -26.79764   27   15    0.98670  -26.79764  2816%   3.5  142s\n",
      "  3734  1784  -25.38623   35   14    0.98670  -26.79764  2816%   3.5  146s\n",
      "  3835  1843  -22.50702   38   16    0.98670  -26.79764  2816%   3.5  150s\n",
      "  4115  1920  -13.17107   47    7    0.98670  -26.79764  2816%   3.6  157s\n",
      "  4292  1961   -7.46059   63    9    0.98670  -26.78968  2815%   3.6  164s\n",
      "  4465  2009  -16.30117   26    4    0.98670  -19.86837  2114%   3.6  171s\n",
      "  4671  2061   -7.86510   44    2    0.98670  -19.04369  2030%   3.6  182s\n",
      "  4864  2062 infeasible   49         0.98670  -18.03242  1928%   3.6  189s\n",
      "  5030  2103   -8.54651   50    8    0.98670  -17.78366  1902%   3.6  197s\n",
      "  5212  2152   -2.39905   59    -    0.98670  -17.36607  1860%   3.7  205s\n",
      "  5404  2215     cutoff   59         0.98670  -16.89561  1812%   3.7  213s\n",
      "  5619  2247     cutoff   55         0.98670  -16.76622  1799%   3.6  220s\n",
      "  5784  2295   -5.27949   50    7    0.98670  -16.46795  1769%   3.7  227s\n",
      "  5967  2337  -13.93874   42   10    0.98670  -16.11857  1734%   3.7  234s\n",
      "  6119  2366  -10.45163   53    7    0.98670  -16.11857  1734%   3.7  238s\n",
      "  6265  2403   -6.58274   61    7    0.98670  -16.11857  1734%   3.7  244s\n",
      "  6394  2419   -5.01206   68    8    0.98670  -16.11857  1734%   3.7  247s\n",
      "  6541  2435   -2.64963   76    7    0.98670  -15.54912  1676%   3.7  253s\n",
      "  6668  2464  -11.61940   29    4    0.98670  -15.42419  1663%   3.8  259s\n",
      "  6826  2496     cutoff   37         0.98670  -15.07318  1628%   3.8  267s\n",
      "  6983  2530     cutoff   41         0.98670  -14.77637  1598%   3.8  272s\n",
      "  7130  2568  -12.07507   29    2    0.98670  -14.53141  1573%   3.8  278s\n",
      "  7284  2607   -9.08354   44    7    0.98670  -14.32485  1552%   3.8  286s\n",
      "  7446  2683     cutoff   50         0.98670  -14.29351  1549%   3.8  294s\n",
      "  7639  2691   -4.55292   69    2    0.98670  -14.07420  1526%   3.8  301s\n",
      "  7791  2717   -2.43281   73    1    0.98670  -13.91925  1511%   3.8  308s\n",
      "  7979  2717   -8.58097   66    4    0.98670  -13.89073  1508%   3.8  317s\n",
      "  8177  2809     cutoff   72         0.98670  -13.78857  1497%   3.8  332s\n",
      "  8357  2917     cutoff   72         0.98670  -13.70812  1489%   3.8  337s\n",
      "  8519  2991   -4.29886   50    2    0.98670  -13.70281  1489%   3.8  342s\n",
      "  8687  3081     cutoff   53         0.98670  -13.41353  1459%   3.9  349s\n",
      "  8899  3218  -10.27086   39    6    0.98670  -13.19295  1437%   3.9  360s\n",
      "  9088  3323   -8.98508   50    9    0.98670  -13.14389  1432%   3.9  368s\n",
      "  9244  3384     cutoff   75         0.98670  -13.05752  1423%   3.9  371s\n",
      "  9392  3458   -9.65001   41    7    0.98670  -13.05752  1423%   3.9  380s\n",
      "  9533  3505   -1.15115   52    3    0.98670  -13.04357  1422%   3.9  388s\n",
      "  9684  3641     cutoff   39         0.98670  -12.71406  1389%   3.9  401s\n",
      "  9913  3784     cutoff   47         0.98670  -12.65592  1383%   3.9  408s\n",
      " 10178  3855   -0.81449   52    2    0.98670  -12.52899  1370%   3.9  416s\n",
      " 10405  3943   -3.13489   60   11    0.98670  -12.41743  1358%   3.9  425s\n",
      " 10610  4058     cutoff   63         0.98670  -12.31778  1348%   3.9  440s\n",
      " 10842  4184   -8.79747   50    7    0.98670  -12.25767  1342%   4.0  450s\n",
      " 11088  4279     cutoff   56         0.98670  -12.16361  1333%   4.0  462s\n",
      " 11304  4372   -4.38776   48    5    0.98670  -12.10803  1327%   4.0  472s\n",
      " 11553  4490   -4.08435   58    2    0.98670  -12.02194  1318%   4.0  485s\n",
      " 11794  4562   -3.28370   61    -    0.98670  -11.87912  1304%   4.0  497s\n",
      " 12065  4721   -3.16954   61    -    0.98670  -11.82957  1299%   4.0  511s\n",
      " 12319  4842   -1.53942   61    2    0.98670  -11.72694  1288%   4.0  519s\n",
      " 12588  4941   -2.64634   53    -    0.98670  -11.63817  1280%   4.0  532s\n",
      " 12825  5067   -7.13953   39    6    0.98670  -11.57888  1273%   4.0  545s\n",
      " 13107  5203   -1.60293   46    2    0.98670  -11.45879  1261%   4.1  555s\n",
      " 13392  5327    0.23056   73    -    0.98670  -11.39457  1255%   4.1  569s\n",
      " 13697  5460   -4.78084   71    5    0.98670  -11.28656  1244%   4.1  583s\n",
      " 13964  5614     cutoff   74         0.98670  -11.20737  1236%   4.1  595s\n",
      " 14262  5761   -4.57493   63    2    0.98670  -11.05783  1221%   4.1  606s\n",
      " 14595  5931   -1.47534   63    5    0.98670  -10.94457  1209%   4.1  620s\n",
      " 14933  6087   -4.98700   56    6    0.98670  -10.87588  1202%   4.1  635s\n",
      " 15245  6228   -0.95856   76    3    0.98670  -10.80013  1195%   4.1  648s\n",
      " 15578  6359   -2.35135   45    3    0.98670  -10.73407  1188%   4.1  662s\n",
      " 15870  6482     cutoff   63         0.98670  -10.63330  1178%   4.2  677s\n",
      " 16186  6527   -5.93126   69    1    0.98670  -10.63330  1178%   4.2  691s\n",
      "H16187  6527                       0.9867012  -10.63330  1178%   4.2  692s\n",
      " 16204  6595   -5.93126   70    5    0.98670  -10.58476  1173%   4.2  695s\n",
      " 16487  6724   -4.59253   73    2    0.98670  -10.49185  1163%   4.2  705s\n",
      "H16807  6780                       0.9867012  -10.44706  1159%   4.2  719s\n",
      " 16858  6855   -2.70082   77    -    0.98670  -10.37611  1152%   4.2  722s\n",
      " 17171  7044   -1.45742   77    2    0.98670  -10.28825  1143%   4.2  734s\n",
      " 17625  7228     cutoff   54         0.98670  -10.22252  1136%   4.3  746s\n",
      " 18173  7504    0.27489   67    2    0.98670  -10.08185  1122%   4.3  771s\n",
      " 18692  7591     cutoff   64         0.98670   -9.97959  1111%   4.3  784s\n",
      " 18839  7607   -2.19674   64   12    0.98670   -9.93597  1107%   4.3  790s\n",
      " 19272  7978   -0.66755   68    2    0.98670   -9.81311  1095%   4.4  807s\n",
      "H19457  7994                       0.9867012   -9.81273  1094%   4.4  812s\n",
      " 19952  8223     cutoff   32         0.98670   -9.69191  1082%   4.4  831s\n",
      " 20593  8492   -1.74358   73    9    0.98670   -9.55803  1069%   4.4  854s\n",
      " 21249  8721   -1.11411   71    2    0.98670   -9.47684  1060%   4.4  874s\n",
      " 21938  9046     cutoff   84         0.98670   -9.34827  1047%   4.5  899s\n",
      " 22674  9236   -0.71039   60    2    0.98670   -9.24971  1037%   4.5  921s\n",
      " 23208  9473     cutoff   62         0.98670   -9.08941  1021%   4.5  937s\n",
      " 23762  9782     cutoff   73         0.98670   -9.05666  1018%   4.6  957s\n",
      " 24497 10056    0.36550   68    2    0.98670   -8.87132   999%   4.6  978s\n",
      " 25155 10240     cutoff   51         0.98670   -8.80396   992%   4.6  993s\n",
      " 25796 10503    0.63306   60    6    0.98670   -8.74774   987%   4.6 1017s\n",
      " 26436 10738   -1.77133   64    8    0.98670   -8.59836   971%   4.7 1039s\n",
      " 27057 10943   -1.38304   69    2    0.98670   -8.53178   965%   4.7 1053s\n",
      " 27637 11198   -5.74408   61   12    0.98670   -8.40692   952%   4.7 1073s\n",
      " 28302 11434     cutoff   72         0.98670   -8.33903   945%   4.7 1094s\n",
      " 28932 11706     cutoff   72         0.98670   -8.26850   938%   4.8 1112s\n",
      " 29557 11877     cutoff   58         0.98670   -8.16541   928%   4.8 1129s\n",
      " 30162 12124   -0.85316   33    2    0.98670   -8.07737   919%   4.8 1151s\n",
      " 30774 12281     cutoff   68         0.98670   -8.01264   912%   4.8 1169s\n",
      " 31476 12522   -1.20373   66    2    0.98670   -7.92042   903%   4.8 1199s\n",
      " 32154 12638     cutoff   33         0.98670   -7.79896   890%   4.8 1218s\n",
      " 32759 12841   -2.06050   63    3    0.98670   -7.74066   884%   4.8 1242s\n",
      " 33334 13027     cutoff   64         0.98670   -7.65685   876%   4.9 1263s\n",
      " 33898 13176     cutoff   64         0.98670   -7.65685   876%   4.9 1280s\n",
      " 34482 13341     cutoff   34         0.98670   -7.50432   861%   4.9 1300s\n",
      " 35066 13498     cutoff   54         0.98670   -7.41115   851%   4.9 1318s\n",
      " 35637 13682     cutoff   60         0.98670   -7.38344   848%   4.9 1340s\n",
      " 36224 13842     cutoff   62         0.98670   -7.29846   840%   4.9 1358s\n",
      " 36744 14011     cutoff   69         0.98670   -7.23272   833%   4.9 1370s\n",
      " 37302 14160   -1.16998   68    6    0.98670   -7.18596   828%   5.0 1384s\n",
      " 37856 14332     cutoff   65         0.98670   -7.09894   819%   5.0 1398s\n",
      " 38298 14361   -2.48474   67    9    0.98670   -7.08551   818%   5.0 1407s\n",
      " 38868 14542   -2.41833   60    -    0.98670   -6.98687   808%   5.0 1422s\n",
      " 39259 14689   -2.90936   61    3    0.98670   -6.95277   805%   5.0 1432s\n",
      " 39830 14839     cutoff   64         0.98670   -6.88161   797%   5.0 1446s\n",
      " 40424 15001   -2.53630   69   12    0.98670   -6.83291   793%   5.0 1460s\n",
      " 41008 15156    0.70151   60    5    0.98670   -6.74505   784%   5.0 1477s\n",
      " 41572 15263   -1.12650   64    5    0.98670   -6.68708   778%   5.1 1487s\n",
      " 41714 15274     cutoff   73         0.98670   -6.68041   777%   5.1 1492s\n",
      " 41975 15349   -1.15644   64    2    0.98670   -6.65378   774%   5.1 1497s\n",
      " 42563 15472   -0.55987   71    3    0.98670   -6.59688   769%   5.1 1519s\n",
      " 42732 15485   -0.72346   73    2    0.98670   -6.58915   768%   5.1 1525s\n",
      " 43011 15584     cutoff   57         0.98670   -6.56092   765%   5.1 1530s\n",
      " 43494 15683     cutoff   58         0.98670   -6.53426   762%   5.1 1544s\n",
      " 43987 15729   -2.05415   48    8    0.98670   -6.51747   761%   5.1 1600s\n",
      " 43990 15731   -3.45342   53    9    0.98670   -6.51747   761%   5.1 1616s\n",
      " 44000 15738   -4.28556   60   10    0.98670   -6.51747   761%   5.1 1620s\n",
      " 44004 15740   -4.10106   44    8    0.98670   -6.51747   761%   5.1 1634s\n",
      " 44005 15743   -6.51747   27   12    0.98670   -6.51747   761%   5.1 1637s\n",
      " 44071 15747   -6.51747   36    9    0.98670   -6.51747   761%   5.1 1640s\n",
      " 44370 15755   -6.51747   48   15    0.98670   -6.51747   761%   5.1 1645s\n",
      " 44513 15762   -6.51747   52   10    0.98670   -6.51747   761%   5.1 1650s\n",
      " 44664 15773   -3.50534   59    7    0.98670   -6.51747   761%   5.1 1656s\n",
      " 44750 15770   -6.51747   40   14    0.98670   -6.51747   761%   5.1 1660s\n",
      " 44946 15773   -6.51747   46   19    0.98670   -6.51747   761%   5.1 1666s\n",
      " 45121 15834   -6.51747   51   24    0.98670   -6.51747   761%   5.2 1670s\n",
      " 45731 16007   -6.51747   69   19    0.98670   -6.51747   761%   5.2 1675s\n",
      " 46330 16052   -2.34284   85   17    0.98670   -6.51747   761%   5.3 1680s\n",
      " 46804 16153   -1.27886   94   14    0.98670   -6.51747   761%   5.3 1685s\n",
      " 47238 16301   -0.08743  102   18    0.98670   -6.51747   761%   5.3 1690s\n",
      " 48144 16503   -5.02105   72   12    0.98670   -6.51747   761%   5.3 1698s\n",
      " 48540 16553     cutoff   63         0.98670   -6.51747   761%   5.4 1704s\n",
      " 48961 16519     cutoff   67         0.98670   -6.51747   761%   5.4 1711s\n",
      " 49457 16672   -6.51747   42    4    0.98670   -6.51747   761%   5.4 1716s\n",
      " 49903 16609   -2.24208   70    9    0.98670   -6.51747   761%   5.4 1723s\n",
      " 50233 16692   -5.11093   69    8    0.98670   -6.51747   761%   5.4 1730s\n",
      " 50520 16609   -4.56842   64    6    0.98670   -6.51747   761%   5.4 1735s\n",
      " 50719 16732     cutoff   86         0.98670   -6.51747   761%   5.4 1740s\n",
      " 51222 16712   -0.79201   88    9    0.98670   -6.51747   761%   5.4 1746s\n",
      " 51613 16834    0.11041   73    6    0.98670   -6.51747   761%   5.4 1755s\n",
      " 52248 16863     cutoff   65         0.98670   -6.51747   761%   5.4 1765s\n",
      " 52781 16847   -2.34009   75    4    0.98670   -6.51747   761%   5.4 1773s\n",
      " 53134 16990   -0.90828   76    2    0.98670   -6.51747   761%   5.5 1780s\n",
      " 53777 17042     cutoff   90         0.98670   -6.51747   761%   5.5 1787s\n",
      " 54499 16911     cutoff   74         0.98670   -6.51747   761%   5.5 1798s\n",
      " 54910 17073     cutoff   78         0.98670   -6.51747   761%   5.5 1807s\n",
      " 55648 16850    0.53930   81    2    0.98670   -6.51747   761%   5.5 1816s\n",
      " 56081 16831     cutoff   85         0.98670   -6.51747   761%   5.5 1828s\n",
      " 56132 17185     cutoff   81         0.98670   -6.51747   761%   5.5 1831s\n",
      " 57041 17250   -2.70311   75    8    0.98670   -6.51747   761%   5.5 1844s\n",
      " 57975 17305 infeasible   67         0.98670   -6.51747   761%   5.5 1860s\n",
      " 58892 17138   -0.64397   73    5    0.98670   -6.51747   761%   5.5 1872s\n",
      " 59367 17298   -1.54435   73    5    0.98670   -6.51747   761%   5.5 1882s\n",
      " 60170 17063     cutoff   72         0.98670   -6.51747   761%   5.5 1895s\n",
      " 60400 17357     cutoff   76         0.98670   -6.51747   761%   5.5 1900s\n",
      " 61578 17090   -3.61059   76   11    0.98670   -6.51747   761%   5.5 1918s\n",
      " 62006 17205   -2.39548   66    2    0.98670   -6.51747   761%   5.5 1931s\n",
      " 62925 16931     cutoff   66         0.98670   -6.51747   761%   5.5 1945s\n",
      " 63315 17054 infeasible   73         0.98670   -6.51747   761%   5.5 1955s\n",
      " 64129 16974    0.28931   75   10    0.98670   -6.51747   761%   5.5 1972s\n",
      " 64490 16869   -4.06277   77    8    0.98670   -6.51747   761%   5.5 1979s\n",
      " 64835 17093   -0.32901   83    2    0.98670   -6.44851   754%   5.5 1986s\n",
      " 65146 17000 infeasible   81         0.98670   -6.44462   753%   5.5 1990s\n",
      " 66002 16975     cutoff   68         0.98670   -6.31312   740%   5.5 2001s\n",
      " 67048 16742 infeasible   78         0.98670   -6.23955   732%   5.5 2013s\n",
      " 67298 16664     cutoff   53         0.98670   -6.21126   729%   5.5 2016s\n",
      " 67573 16832     cutoff   75         0.98670   -6.17955   726%   5.5 2021s\n",
      " 68690 16700    0.19503   83    8    0.98670   -6.07242   715%   5.5 2039s\n",
      " 69741 16447     cutoff   80         0.98670   -5.94618   703%   5.5 2053s\n",
      " 70220 16564 infeasible   73         0.98670   -5.90005   698%   5.5 2061s\n",
      " 71306 16435   -2.62361   83    2    0.98670   -5.81277   689%   5.5 2074s\n",
      " 71725 16314     cutoff   82         0.98670   -5.79882   688%   5.5 2082s\n",
      " 72327 16156     cutoff   50         0.98670   -5.72922   681%   5.5 2088s\n",
      " 72535 16093     cutoff   84         0.98670   -5.70889   679%   5.5 2091s\n",
      " 72917 16031   -2.98184   79   12    0.98670   -5.60971   669%   5.5 2099s\n",
      " 73429 16077 infeasible   84         0.98670   -5.57724   665%   5.5 2113s\n",
      " 74641 15756 infeasible   73         0.98670   -5.48323   656%   5.5 2134s\n",
      " 74710 15735     cutoff   72         0.98670   -5.47521   655%   5.5 2135s\n",
      " 75122 15801     cutoff   60         0.98670   -5.40107   647%   5.5 2151s\n",
      " 76220 15524     cutoff   85         0.98670   -5.29970   637%   5.5 2174s\n",
      " 76274 15512     cutoff   59         0.98670   -5.29867   637%   5.6 2177s\n",
      " 76689 15556     cutoff   80         0.98670   -5.24581   632%   5.6 2185s\n",
      " 77742 15252     cutoff   82         0.98670   -5.19384   626%   5.6 2198s\n",
      " 78238 15255   -0.76320   80   11    0.98670   -5.13600   621%   5.6 2205s\n",
      " 79195 15105     cutoff   77         0.98670   -5.09850   617%   5.6 2216s\n",
      " 80148 14873     cutoff   67         0.98670   -4.97326   604%   5.6 2231s\n",
      " 80432 14798     cutoff   84         0.98670   -4.95650   602%   5.6 2237s\n",
      " 80618 14885   -1.88566   73    9    0.98670   -4.94131   601%   5.6 2241s\n",
      " 81578 14760     cutoff   62         0.98670   -4.88485   595%   5.6 2256s\n",
      " 82520 14552   -1.76262   83   13    0.98670   -4.85736   592%   5.6 2268s\n",
      " 83053 14562   -1.46309   69    8    0.98670   -4.75349   582%   5.6 2275s\n",
      " 83991 14386   -1.40847   73    7    0.98670   -4.68311   575%   5.6 2286s\n",
      " 84991 14091    0.32530   79    5    0.98670   -4.61396   568%   5.6 2297s\n",
      " 85479 14036     cutoff   72         0.98670   -4.55361   561%   5.6 2310s\n",
      " 86445 13905   -0.24585   79    2    0.98670   -4.50241   556%   5.6 2329s\n",
      " 87517 13599     cutoff   59         0.98670   -4.43958   550%   5.6 2345s\n",
      " 87928 13480     cutoff   89         0.98670   -4.40895   547%   5.6 2353s\n",
      " 87981 13554   -1.13575   71    8    0.98670   -4.39949   546%   5.6 2356s\n",
      " 88919 13324     cutoff   73         0.98670   -4.34434   540%   5.6 2369s\n",
      " 89846 13061     cutoff   83         0.98670   -4.26874   533%   5.6 2381s\n",
      " 90299 13029     cutoff   73         0.98670   -4.21499   527%   5.6 2389s\n",
      " 91263 12747   -0.25111   81    2    0.98670   -4.15794   521%   5.7 2398s\n",
      " 91792 12853   -2.10608   48    2    0.98670   -4.12575   518%   5.7 2406s\n",
      " 92740 12934     cutoff   83         0.98670   -4.05327   511%   5.7 2413s\n",
      " 93583 12943     cutoff   65         0.98670   -4.03434   509%   5.7 2423s\n",
      " 94103 13045   -2.37868   82   12    0.98670   -3.96495   502%   5.7 2429s\n",
      " 95157 13026     cutoff   81         0.98670   -3.88824   494%   5.7 2440s\n",
      " 95731 13070   -1.73160   80    7    0.98670   -3.84998   490%   5.7 2448s\n",
      " 96021 13078     cutoff   85         0.98670   -3.84446   490%   5.7 2453s\n",
      " 96604 13129 infeasible   82         0.98670   -3.79068   484%   5.7 2462s\n",
      " 97538 13149     cutoff   78         0.98670   -3.74079   479%   5.7 2471s\n",
      " 97887 13157   -1.96754   78    8    0.98670   -3.72933   478%   5.7 2475s\n",
      " 98916 13247 infeasible   87         0.98670   -3.64238   469%   5.7 2485s\n",
      " 99380 13294 infeasible   71         0.98670   -3.61139   466%   5.7 2496s\n",
      " 100391 13286     cutoff   81         0.98670   -3.55065   460%   5.7 2510s\n",
      " 100842 13297     cutoff   79         0.98670   -3.54306   459%   5.7 2515s\n",
      " 102193 13399   -1.33845   83    9    0.98670   -3.43574   448%   5.7 2529s\n",
      " 102721 13367   -0.81543   97    8    0.98670   -3.40234   445%   5.7 2534s\n",
      " 103824 13463   -1.34001   84    9    0.98670   -3.33696   438%   5.7 2548s\n",
      " 104980 13421     cutoff   76         0.98670   -3.25422   430%   5.7 2557s\n",
      " 105104 13427   -1.49081   87    -    0.98670   -3.25237   430%   5.7 2560s\n",
      " 105474 13310   -0.84497   86    7    0.98670   -3.22596   427%   5.7 2565s\n",
      " 106339 13316    0.18080   88   17    0.98670   -3.18852   423%   5.7 2575s\n",
      " 107844 13341   -1.88455   83    9    0.98670   -3.12002   416%   5.7 2594s\n",
      " 108294 13322     cutoff   81         0.98670   -3.07124   411%   5.7 2600s\n",
      " 109944 13308     cutoff   84         0.98670   -2.98129   402%   5.7 2613s\n",
      " 110452 13269   -1.10609   75    8    0.98670   -2.95081   399%   5.7 2619s\n",
      " 110750 13272    0.01355   80   12    0.98670   -2.94409   398%   5.8 2621s\n",
      " 112099 13222     cutoff   78         0.98670   -2.85412   389%   5.8 2634s\n",
      " 112504 13228     cutoff   83         0.98670   -2.84605   388%   5.8 2636s\n",
      " 113674 13057   -0.39665   80    5    0.98670   -2.76906   381%   5.8 2646s\n",
      " 114255 12936 infeasible   73         0.98670   -2.72307   376%   5.8 2656s\n",
      " 114904 12909   -0.70103   84   14    0.98670   -2.71649   375%   5.8 2664s\n",
      " 115817 12803   -2.24684   76    3    0.98670   -2.64189   368%   5.8 2670s\n",
      " 116408 12725 infeasible   64         0.98670   -2.58755   362%   5.8 2676s\n",
      " 116784 12737 infeasible   86         0.98670   -2.58237   362%   5.8 2681s\n",
      " 117007 12701     cutoff   83         0.98670   -2.55135   359%   5.8 2685s\n",
      " 117653 12582   -0.29024   85   12    0.98670   -2.53901   357%   5.8 2691s\n",
      "H117782 12586                       0.9867012   -2.53901   357%   5.8 2693s\n",
      " 118719 12416   -2.47697   71    2    0.98670   -2.47697   351%   5.8 2699s\n",
      " 118813 12421     cutoff   82         0.98670   -2.47697   351%   5.8 2701s\n",
      " 119268 12208     cutoff   75         0.98670   -2.44233   348%   5.8 2707s\n",
      " 120024 12125 infeasible   70         0.98670   -2.43281   347%   5.8 2719s\n",
      " 120401 12140   -0.47409   84   12    0.98670   -2.41833   345%   5.8 2725s\n",
      " 121052 12087   -0.12609   80    3    0.98670   -2.39548   343%   5.8 2734s\n",
      " 121638 12072     cutoff   87         0.98670   -2.39548   343%   5.8 2739s\n",
      " 122690 11987   -1.32919   82    9    0.98670   -2.28546   332%   5.8 2742s\n",
      " 123126 11995   -1.30652   77    2    0.98670   -2.27664   331%   5.8 2746s\n",
      " 123968 11959     cutoff   70         0.98670   -2.20254   323%   5.8 2750s\n",
      " 125029 11892   -0.30184   47    7    0.98670   -2.17013   320%   5.8 2755s\n",
      " 125542 11759    0.67123   89    7    0.98670   -2.14734   318%   5.8 2760s\n",
      " 126401 11662    0.19270   88    9    0.98670   -2.11511   314%   5.8 2769s\n",
      " 126620 11665 infeasible   89         0.98670   -2.11511   314%   5.8 2771s\n",
      " 127250 11582   -1.08157   87    5    0.98670   -2.04817   308%   5.8 2777s\n",
      " 128628 11482   -0.32047   84    7    0.98670   -2.01628   304%   5.8 2784s\n",
      " 129121 11489    0.63791   81    2    0.98670   -2.01628   304%   5.8 2787s\n",
      " 129955 11276     cutoff   86         0.98670   -1.94145   297%   5.8 2797s\n",
      " 131184 11184    0.18642   86    5    0.98670   -1.88046   291%   5.8 2801s\n",
      " 132479 10927   -0.09970   89    9    0.98670   -1.81244   284%   5.9 2808s\n",
      " 133175 10874   -1.68654   83   12    0.98670   -1.76116   278%   5.9 2814s\n",
      " 134307 10729     cutoff   62         0.98670   -1.72193   275%   5.9 2819s\n",
      " 135022 10574   -0.34248   83   12    0.98670   -1.67133   269%   5.9 2824s\n",
      " 135718 10448 infeasible   82         0.98670   -1.63526   266%   5.9 2829s\n",
      " 136392 10318     cutoff   78         0.98670   -1.60759   263%   5.9 2837s\n",
      " 137137 10138   -0.58744   83    4    0.98670   -1.57958   260%   5.9 2843s\n",
      " 137848 10032   -1.25217   87    6    0.98670   -1.54915   257%   5.9 2849s\n",
      " 138591  9908     cutoff   78         0.98670   -1.50881   253%   5.9 2853s\n",
      " 139633  9753     cutoff   94         0.98670   -1.46112   248%   5.9 2856s\n",
      " 139989  9763     cutoff   94         0.98670   -1.45841   248%   5.9 2861s\n",
      " 140326  9628     cutoff   83         0.98670   -1.43712   246%   5.9 2865s\n",
      " 141068  9397   -0.49808   87   15    0.98670   -1.40691   243%   5.9 2870s\n",
      " 141680  9407    0.33292   86    5    0.98670   -1.40691   243%   5.9 2875s\n",
      " 142672  9005   -0.99069   72    5    0.98670   -1.38304   240%   5.9 2883s\n",
      " 144006  8625 infeasible   76         0.98670   -1.28314   230%   5.9 2886s\n",
      " 145422  8184   -0.57314   56   11    0.98670   -1.20270   222%   5.9 2891s\n",
      " 147622  7463     cutoff   81         0.98670   -1.07280   209%   5.9 2897s\n",
      " 148370  7271   -0.15473   81   13    0.98670   -1.03176   205%   5.9 2907s\n",
      "H148458  7271                       0.9867012   -1.03176   205%   5.9 2908s\n",
      " 149038  7244     cutoff   88         0.98670   -0.98958   200%   5.9 2913s\n",
      "H149043  7244                       0.9867012   -0.98958   200%   5.9 2914s\n",
      " 149147  6927     cutoff   88         0.98670   -0.98712   200%   5.9 2916s\n",
      "H150632  6593                       0.9867012   -0.91838   193%   5.9 2920s\n",
      " 152723  5690     cutoff   87         0.98670   -0.76643   178%   5.9 2926s\n",
      " 154494  5134   -0.16602  108   18    0.98670   -0.74572   176%   6.0 2931s\n",
      " 156311  4482    0.05844   91    7    0.98670   -0.56546   157%   6.0 2936s\n",
      " 158964  3324 infeasible   89         0.98670   -0.40028   141%   6.0 2940s\n",
      "H161004  2356                       0.9867012   -0.19727   120%   6.0 2944s\n",
      " 161556  2357     cutoff   77         0.98670   -0.16224   116%   6.0 2945s\n",
      " 162970  1136     cutoff   92         0.98670   -0.00059   100%   6.0 2950s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 1\n",
      "  MIR: 5\n",
      "  Lazy constraints: 2347\n",
      "\n",
      "Explored 164472 nodes (979042 simplex iterations) in 2953.52 seconds\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 5: 0.986701 0.986701 0.986701 ... 0.990373\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 9.867011615913e-01, best bound 9.867011615913e-01, gap 0.0000%\n",
      "\n",
      "User-callback calls 347441, time in user-callback 2704.57 sec\n",
      "dataSet N50_d40_\n",
      "x = [-0.0, -0.0, -0.0, -0.0, 1.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, 0.0, 0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 1.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, 0.0, 0.0, 0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, 0.0, -0.0, -0.0, 0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, 0.0, -0.0, 0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, 0.0, -0.0, -0.0, 0.0, 0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, 0.0, -0.0, 0.0, 0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, 0.0, -0.0, 0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, 0.0, 0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, 0.0, -0.0, -0.0, -0.0, 0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, 0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, 0.0, 0.0, -0.0, 0.0, -0.0, -0.0, 0.0, -0.0, -0.0, 0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, 0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, 0.0, 0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, 0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, 0.0, -0.0, -0.0, -0.0, 0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, 0.0, -0.0, 0.0, 0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, 0.0, -0.0, 0.0, -0.0, -0.0, 0.0, -0.0, -0.0, 0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 1.61325e-10, -0.0, -0.0, 0.0, -0.0, 0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, 0.0, -0.0, -0.0, -0.0, -0.0, 0.0, 0.0, -0.0, -0.0, -0.0, 0.0, -0.0, 0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, 0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, 0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, 0.0]\n",
      "x_i = [5, 81, 782]\n",
      "theta = 0.9867011615912933\n",
      "M_set = 404\n",
      "y = [0.0854152, 0.0054319, 0.39549, 0.0395482, 0.00807968, 0.0748314, 0.0125745, 0.00323607, 0.0136343, 0.0419715, 0.0116682, 0.00909369, 0.0320574, 0.0132497, 0.0654111, 0.178472, 0.00983519]\n",
      "M_pos = Array{Int64,1}[[1], [4], [5, 372], [13, 796], [3, 58], [6], [9], [16, 300], [7, 14, 27], [7, 15, 935], [7, 11], [7, 17, 44], [7, 832], [7, 8, 121], [12, 16], [2, 152], [10, 484, 925]]\n",
      "Node count = 164472.0\n"
     ]
    }
   ],
   "source": [
    "ins = 4#ARGS[1] #:10 #2,3, do 4 first, 5\n",
    "dataSet = \"N50_d40_\"\n",
    "println(\"Running...\")\n",
    "global prob = \"\" #\"L\"\n",
    "#     include(\"./TestInstances/\"*fileName*\".jl\")\n",
    "global q =[]\n",
    "include(\"./TestInstances/\"*dataSet*string(ins)*\".jl\")\n",
    "global numArcs = length(arcs[:,1])\n",
    "global lb = 1\n",
    "global ub = 999\n",
    "# println(\"1\")\n",
    "function setQ(prob)\n",
    "    global lb, ub, numArcs, q\n",
    "    if prob == \"L\"\n",
    "        lb = 1\n",
    "        ub = 333\n",
    "    elseif prob == \"M\"\n",
    "        lb = 334\n",
    "        ub = 666\n",
    "    elseif prob == \"H\"\n",
    "        lb = 667\n",
    "        ub = 999\n",
    "    end\n",
    "    new_q = rand(lb:ub, numArcs)./1000\n",
    "       \n",
    "    return new_q\n",
    "end\n",
    "# println(\"2\")\n",
    "if prob != \"\"\n",
    "    q = setQ(prob)\n",
    "end\n",
    "# println(\"q = \", q)\n",
    "# q = [0.28, 0.23, 0.033, 0.257, 0.208, 0.037, 0.009, 0.269, 0.302, 0.167, 0.098, 0.288, 0.187]\n",
    "# println(\"3\")\n",
    "#     global numArcs, arcs, d_x, q, b_x, origin, destination, R, d_y, b_y\n",
    "#     global newP, newM, P_set, M_set, numPaths,numY\n",
    "    \n",
    "    include(\"./functionEnumFeasX.jl\")\n",
    "    include(\"./functionFindQ.jl\")\n",
    "    include(\"./functionGetCost_SP.jl\")\n",
    "\n",
    "    include(\"./functionShortestPathBellmanFord.jl\")\n",
    "    include(\"./functionGenMonitoring.jl\")\n",
    "    include(\"./functionLP_findM.jl\")\n",
    "    \n",
    "\n",
    "        \n",
    "#     global X_feas = EnumX(arcs, b_x, numArcs, d_x)\n",
    "#     global EnumY = EnumX(arcs, b_y, numArcs, d_y)\n",
    "    M_start = findall(d_x.<=b_x)\n",
    "    global M_set = [[M_start[1]]]#[EnumY[1]] #EnumX(arcs, b_y, numArcs, d_y)\n",
    "    global numY = 1 \n",
    "    global R = -sum(log10(1-q_) for q_ in q)  #10^6#0^6\n",
    "    println(\"R = \", R)\n",
    "    path, gx = shortestPath_BellmanFord(q, arcs, numArcs, origin, destination)\n",
    "    arcsinPath = findall(path.>0)\n",
    "    global P_set = [arcsinPath]\n",
    "global P_pos = []\n",
    "#     global P_set = [P[1]]\n",
    "\n",
    "#     global x_now, current_Obj, y_now\n",
    "\n",
    "#     println(\"X_feas = \", X_feas)\n",
    "#     println(\"Starting M_set \", M_set, \", P_set = \", P_set)\n",
    "\n",
    "global y_sol = []\n",
    "#     global \n",
    "global numPaths = 1\n",
    "global newP = true\n",
    "global newM = true\n",
    "global iter = 0\n",
    "#     global theta_now = -1e12\n",
    "#     global inner_Obj = 1-1e12\n",
    "conRefNum = 20# max(200,2*length(P_set))\n",
    "con = Array{JuMP.ConstraintRef}(undef, conRefNum)\n",
    "global k = 0\n",
    "global rootOptGap = 0\n",
    "model = direct_model(Gurobi.Optimizer())\n",
    "#     set_optimizer_attribute(model, \"Presolve\", 0)\n",
    "#     set_optimizer_attribute(model, \"Precrush\", 1)\n",
    "#     set_optimizer_attribute(model, \"DualReductions\", 0)\n",
    "#     set_optimizer_attribute(model, \"PreQLinearize\", 0)\n",
    "#     set_optimizer_attribute(model, \"Heuristics\", 0)\n",
    "#     set_optimizer_attribute(model, \"MIPGap\", 0)\n",
    "set_optimizer_attribute(model, \"LazyConstraints\", 1)\n",
    "# set_optimizer_attribute(model, \"OutputFlag\", 0)\n",
    "global loc = \"./Documents/GitHub/UncertainTarget/EnumX_RowCol2ndStage/TestInstances/\"\n",
    "# println(\"Here\")\n",
    "# set_optimizer_attribute(model, \"LogFile\", loc*\"L_\"*dataSet*prob*\"_\"*string(ins)*\".log\")\n",
    "# Presolve = 0,\n",
    "#         PreCrush = 1,\n",
    "#         Heuristics = 0,\n",
    "\n",
    "@variable(model, x[1:numArcs], Bin)\n",
    "@variable(model, theta >= 1-R)#1e6)\n",
    "@objective(model, Min, theta)\n",
    "@constraint(model, sum(d_x[a]*x[a] for a=1:numArcs) <= b_x)\n",
    "    \n",
    "#     @variable(model, 0 <= x <= 2.5, Int)\n",
    "#     @variable(model, 0 <= y <= 2.5, Int)\n",
    "#     @objective(model, Max, y)\n",
    "#     println(\"\\nM_set = \", M_set,\" \\t P_set = \", P_set)\n",
    "global last_theta = -1e6 - 1\n",
    "global start = time()\n",
    "cb_calls = Cint[]\n",
    "\n",
    "function my_callback_function(cb_data, cb_where::Cint)\n",
    "    global numArcs, arcs, d_x, q, b_x, origin, destination, R, d_y, b_y, y_sol\n",
    "    global newP, newM, P_set, M_set, numPaths,numY, iter, theta_now, inner_Obj\n",
    "    global k, last_theta\n",
    "    global P_pos\n",
    "        # You can reference variables outside the function as normal\n",
    "        push!(cb_calls, cb_where)\n",
    "        iter += 1\n",
    "    \n",
    "#         println(\"\\niter = \", iter)\n",
    "#         println(\"\\nM_set = \", M_set,\" \\t P_set = \", P_set)\n",
    "        # You can select where the callback is run\n",
    "#         if cb_where != GRB_CB_MIPSOL && cb_where != GRB_CB_MIPNODE\n",
    "#             return\n",
    "#         end\n",
    "        \n",
    "        # You can query a callback attribute using GRBcbget\n",
    "        if cb_where == GRB_CB_MIPSOL #|| cb_where == GRB_CB_MIPNODE\n",
    "            resultP = Ref{Cint}()\n",
    "            GRBcbget(cb_data, cb_where, GRB_CB_MIPNODE_STATUS, resultP)\n",
    "#         println(, \" \", MOI.get(model, MOI.NodeCount())\n",
    "#         println(\"cb_data \", cb_data)\n",
    "#         println(\"cb_where \", cb_where)\n",
    "#         println(\"GRB_CB_MIPNODE_STATUS \", GRB_CB_MIPNODE_STATUS)   \n",
    "        # Before querying `callback_value`, you must call:\n",
    "        Gurobi.load_callback_variable_primal(cb_data, cb_where)\n",
    "#         if resultP[] != GRB_OPTIMAL\n",
    "#             return  # Solution is something other than optimal.\n",
    "#         end\n",
    "#         if resultP == GRB_OPTIMAL\n",
    "#             println(\"\\niter = \", iter)\n",
    "            x_val = callback_value.(Ref(cb_data), x)\n",
    "            theta_val = callback_value(cb_data, theta)\n",
    "#             println(\"x_val = \", findall(x_val.>0))#, \"\\t theta_val\", theta_val)\n",
    "            P_set, M_set, lambda, pi_, inner_Obj, y_sol = solveLP_findM(x_val)\n",
    "#             println(\"M = \", length(M_set), \"\\t P = \", length(P_set)) \n",
    "#             println(\"P = \", P_set)\n",
    "#             println(\"theta_val = \", theta_val, \"\\tinner_Obj = \", inner_Obj)\n",
    "#             lambda_pos = findall(lambda.>0)\n",
    "#             P_pos = P_set[lambda_pos]\n",
    "#             println(\"lambda = \", lambda, \"\\t pi_ = \", pi_)\n",
    "            numPaths = length(P_set)\n",
    "            numY = length(M_set)\n",
    "\n",
    "            TOL = 10^(-3)\n",
    "#             println(\"(inner_Obj - theta_val) = \", (inner_Obj - theta_val))\n",
    "            \n",
    "#             println(\"TOL = \", TOL)\n",
    "            if (inner_Obj - theta_val) > TOL  \n",
    "                k+=1 \n",
    "                con_ = @build_constraint(theta >= sum(lambda[i]*(-R)*sum(x[a] for a in P_set[i]) for i=1:numPaths) + pi_)\n",
    "#                 println(\"Added con\")\n",
    "#                 println(\"Type = \", typeof(con_))\n",
    "#             cut_vio = (sum(lambda[i]*(-R)*sum(x_val[a] for a in P_set[i]) for i=1:numPaths) + pi_) - theta_val\n",
    "#                 println(\"Add con : cut violation = \", cut_vio)\n",
    "#                 println(theta, \">=\", sum(lambda[i]*(-R)*sum(x[a] for a in P_set[i]) for i=1:numPaths) + pi_)\n",
    "                \n",
    "                w_con = MOI.submit(model, MOI.LazyConstraint(cb_data), con_)\n",
    "#                 println(\"Typeof = \", typeof(w_con))\n",
    "#             MOI.set(model, Gurobi.Lazy(), con[k], 2)\n",
    "#             MOI.set(model, Gurobi.ConstraintAttribute(\"lazy\"), con, 2)\n",
    "            end\n",
    "#         if last_theta > theta_val\n",
    "#             GRBterminate(backend(model))\n",
    "#         else\n",
    "#             last_theta = theta_val\n",
    "#         end\n",
    "#         end \n",
    "    end\n",
    "        \n",
    "       \n",
    "        \n",
    "#         if iter > 12\n",
    "#             # You can terminate the callback as follows:\n",
    "#             GRBterminate(backend(model))\n",
    "#         end\n",
    "    return\n",
    "end\n",
    "#     You _must_ set this parameter if using lazy constraints.\n",
    "    MOI.set(model, MOI.RawParameter(\"LazyConstraints\"), 1)\n",
    "    MOI.set(model, Gurobi.CallbackFunction(), my_callback_function)\n",
    "#     println(model)\n",
    "    optimize!(model)\n",
    "    \n",
    "#     println(model)\n",
    "    totalTime = time() - start\n",
    "    x_sol = JuMP.value.(x)\n",
    "    theta_sol = JuMP.value.(theta)\n",
    "    println(\"dataSet \", dataSet*prob)\n",
    "    println(\"x = \", x_sol)\n",
    "    println(\"x_i = \", findall(x_sol.>0))\n",
    "    println(\"theta = \", theta_sol)\n",
    "    println(\"M_set = \", length(M_set))\n",
    "    y_pos = findall(y_sol .> 0)\n",
    "    println(\"y = \", y_sol[y_pos])\n",
    "    println(\"M_pos = \", M_set[y_pos])\n",
    "    nodeCount = MOI.get(model, MOI.NodeCount())\n",
    "    println(\"Node count = \", nodeCount)\n",
    "\n",
    "int_arc = findall(x_sol.>0)\n",
    "\n",
    "global myP = []\n",
    "for n = 1: numPaths #path in P_set\n",
    "    global myP\n",
    "    path = P_set[n]\n",
    "    int_path = intersect(path, int_arc)\n",
    "    if length(int_path) == 0\n",
    "        push!(myP,n)\n",
    "    end\n",
    "end\n",
    "P_pos = P_set[myP]\n",
    "# println(\"P_pos = \", P_pos)\n",
    "\n",
    "#Get P_pos\n",
    "# timesFile = open(\"./TestInstances/P_\"*dataSet*prob*\".txt\", \"a\")\n",
    "# println(timesFile, dataSet*prob, \"; Ins \", ins, \"; Time \", totalTime, \"; theta \", theta_sol,\"; x_sol \", findall(x_sol.>0),\"; M_select \", M_set[y_pos], \"; y_sol \", y_sol[y_pos], \"; Iter \", iter, \"; M_len \", length(M_set), \"; P_len \", length(P_set), \"; NodeCount \", nodeCount)\n",
    "# println(timesFile, \"P_pos = \", P_pos)\n",
    "# close(timesFile)\n",
    "\n",
    "#Get P_set only\n",
    "timesFile = open(\"./TestInstances/P_set_only_\"*dataSet*prob*string(ins)*\".jl\", \"a\")\n",
    "println(timesFile, \"P_set = \", P_set)\n",
    "close(timesFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3]\n",
      "[3, 2]\n",
      "[2, 8]\n",
      "[8, 6]\n",
      "[6, 10]\n"
     ]
    }
   ],
   "source": [
    "dataSet = \"N10_d10_\"\n",
    "ins = 1\n",
    "prob = \"\"\n",
    "global q =[]\n",
    "include(\"./TestInstances/\"*dataSet*string(ins)*\".jl\")\n",
    "\n",
    "for a in [1, 5, 4, 11, 9]\n",
    "    println(arcs[a, :])\n",
    "end\n",
    "# M_pos = Array{Int64,1}[[1], [4], [5, 372], [13, 796], [3, 58], [6], [9], [16, 300], [7, 14, 27], [7, 15, 935], [7, 11], [7, 17, 44], [7, 832], [7, 8, 121], [12, 16], [2, 152], [10, 484, 925]]\n",
    "# y = [0.0854152, 0.0054319, 0.39549, 0.0395482, 0.00807968, 0.0748314, 0.0125745, 0.00323607, 0.0136343, 0.0419715, 0.0116682, 0.00909369, 0.0320574, 0.0132497, 0.0654111, 0.178472, 0.00983519]\n",
    "# P_pos = Array{Int64,1}[[7, 463], [4, 355], [1, 113, 355], [10, 697], [8, 652, 697], [11, 750], [2, 164, 750], [3, 306, 750], [6, 384, 750], [12, 777], [13, 796], [17, 935], [3, 58, 295], [2, 74, 148], [9, 74, 656], [2, 103, 149], [6, 103, 373], [2, 146, 162, 653, 781], [11, 146, 746, 781], [6, 146, 384, 746, 781], [15, 186, 832], [16, 186, 883], [2, 162, 235, 641], [11, 20, 235, 746, 778], [6, 20, 235, 384, 746, 778], [11, 146, 745, 774, 781], [6, 146, 384, 745, 774, 781], [11, 20, 235, 745, 774, 778], [6, 20, 235, 384, 745, 774, 778], [2, 153, 293], [9, 293, 659], [6, 355, 378], [11, 355, 736], [2, 164, 355, 736], [6, 355, 384, 736], [2, 162, 355, 653, 784], [11, 355, 746, 784], [6, 355, 384, 746, 784], [6, 146, 387, 917], [11, 355, 745, 774, 784], [6, 355, 384, 745, 774, 784], [6, 355, 385, 837], [11, 355, 748, 837], [6, 355, 384, 748, 837], [9, 669, 750], [9, 103, 657], [9, 146, 669, 746, 781], [9, 20, 235, 669, 746, 778], [9, 146, 669, 745, 774, 781], [9, 355, 669, 736], [9, 355, 669, 746, 784], [14, 146, 830, 917], [9, 355, 669, 745, 774, 784], [9, 355, 669, 748, 837], [14, 44, 74, 830, 916], [16, 103, 882], [14, 20, 235, 818], [16, 293, 886], [16, 355, 888], [14, 23, 355, 818], [16, 78, 146, 882], [16, 85, 355, 882], [16, 239, 355, 884], [16, 281, 420, 886], [16, 262, 443, 885], [16, 282, 443, 886], [16, 261, 394, 443, 885], [16, 258, 300, 394, 443, 885], [15, 45, 109, 235, 850, 916], [12, 44, 74, 774, 779], [12, 103, 774, 780], [12, 44, 74, 776, 830, 916], [12, 103, 776, 829, 882], [12, 146, 774, 781], [12, 146, 776, 830, 917], [13, 44, 74, 779], [13, 103, 780], [13, 146, 781], [13, 186, 793, 829, 883], [8, 44, 74, 653, 779], [8, 235, 641], [17, 44, 74, 916], [15, 293, 834], [17, 45, 109, 235, 916], [3, 44, 74, 295], [15, 355, 837], [2, 168, 186, 918], [2, 162, 355, 655, 837], [12, 257, 293, 766], [12, 420, 768], [12, 262, 443, 766], [14, 103, 829, 882], [14, 150, 189, 235, 819], [2, 167, 355, 888], [2, 23, 147, 355], [13, 355, 784], [3, 146, 297], [14, 78, 146, 829, 882], [17, 146, 917], [8, 18, 106, 146, 640], [14, 150, 189, 221, 355, 819], [2, 44, 74, 168, 916], [2, 162, 652, 697], [2, 146, 168, 917], [1, 122, 697], [2, 18, 107, 147, 186], [2, 78, 146, 149], [1, 121, 652, 697], [1, 74, 105], [1, 103, 121, 653, 780], [1, 103, 124, 829, 882], [1, 106, 146], [8, 443, 644], [14, 80, 196, 443, 829, 882], [12, 379, 394, 443, 767], [1, 121, 463, 645], [16, 263, 463, 885], [1, 127, 935], [16, 283, 528, 886], [2, 85, 149, 355], [2, 162, 221, 355, 641], [2, 162, 463, 645], [16, 78, 136, 463, 882], [3, 186, 310, 832], [16, 619, 891], [3, 186, 311, 918], [8, 528, 647], [2, 78, 136, 149, 463], [1, 127, 463, 925], [1, 127, 186, 918], [1, 66, 105, 463], [16, 89, 528, 882], [1, 52, 114, 357, 528], [2, 88, 149, 463], [2, 157, 528], [12, 411, 497, 528, 768], [2, 162, 528, 647], [2, 89, 149, 528], [14, 830, 935], [1, 127, 380, 528, 923], [2, 78, 135, 149, 380, 528], [1, 30, 104, 619], [2, 150, 202, 593], [2, 162, 619, 650], [12, 619, 770], [2, 162, 497, 528, 646], [15, 420, 840], [15, 443, 841], [15, 262, 443, 833], [15, 282, 443, 834], [15, 394, 443, 839], [15, 323, 394, 443, 836], [3, 309, 830, 935], [13, 793, 830, 935], [3, 310, 850, 935], [13, 794, 850, 935], [13, 20, 235, 778], [15, 379, 394, 443, 838], [8, 146, 655, 850, 917], [3, 103, 296], [10, 694, 777], [10, 103, 676], [10, 103, 695, 780], [10, 46, 146, 675], [10, 48, 186, 675], [10, 20, 235, 674], [10, 45, 107, 186, 675], [10, 45, 109, 235, 675], [10, 46, 130, 235, 675], [8, 103, 653, 780], [15, 146, 850, 917], [17, 186, 918], [6, 384, 745, 777], [16, 257, 293, 885], [16, 257, 281, 420, 885], [16, 488, 889], [16, 257, 283, 528, 885], [17, 130, 235, 917], [14, 58, 830, 916], [6, 385, 463, 842], [11, 463, 748, 842], [6, 384, 463, 748, 842], [4, 343, 384, 745, 777], [4, 343, 385, 463, 842], [15, 463, 842], [9, 186, 669, 748, 850, 918], [16, 349, 593, 888], [7, 456, 697], [7, 355, 456, 681], [3, 306, 745, 777], [3, 74, 306, 729], [2, 164, 186, 745, 776, 830, 918], [2, 164, 186, 748, 850, 918], [2, 20, 147, 235], [7, 18, 113, 355, 454, 640], [7, 18, 113, 355, 458, 778], [7, 454, 652, 697], [7, 457, 777], [7, 74, 444], [7, 103, 455, 657], [7, 186, 446], [3, 299, 355, 362], [7, 355, 458, 784], [7, 186, 455, 669, 748, 832], [13, 355, 794, 837], [2, 151, 239, 355], [7, 355, 455, 672, 888], [7, 18, 113, 355, 460, 818], [7, 45, 113, 355, 460, 830, 916], [7, 45, 113, 355, 455, 669, 748, 850, 916], [7, 420, 455, 662], [7, 146, 457, 774, 781], [7, 78, 146, 455, 657], [7, 77, 107, 186, 455, 657], [10, 355, 681], [7, 77, 113, 355, 455, 657], [7, 355, 460, 829, 888], [7, 77, 113, 355, 460, 829, 882], [7, 239, 355, 448], [7, 189, 235, 447], [7, 355, 457, 776, 829, 888], [7, 18, 113, 355, 457, 776, 818], [7, 77, 113, 355, 457, 776, 829, 882], [7, 239, 355, 457, 776, 829, 884], [7, 150, 189, 218, 239, 355, 445], [7, 257, 293, 457, 766], [7, 420, 457, 768], [7, 262, 443, 457, 766], [7, 379, 394, 443, 457, 767], [7, 450, 497, 528], [3, 186, 309, 830, 918], [7, 61, 239, 355, 444], [3, 48, 186, 295], [7, 452, 593], [7, 457, 619, 770], [2, 18, 109, 147, 235], [2, 150, 189, 235], [2, 150, 195, 420], [2, 155, 443], [2, 150, 196, 443], [2, 45, 109, 168, 235, 916], [2, 153, 281, 420], [2, 152, 262, 443], [2, 153, 282, 443], [2, 154, 394, 443], [2, 152, 263, 463], [2, 156, 488], [2, 153, 283, 528], [2, 156, 475, 528], [2, 156, 474, 497, 528], [2, 154, 396, 593], [2, 160, 619], [2, 154, 397, 619], [2, 155, 435, 619], [2, 154, 394, 435, 619], [2, 161, 639], [2, 155, 437, 697], [2, 154, 394, 437, 697], [2, 154, 399, 715], [2, 150, 197, 463], [2, 155, 433, 593], [2, 154, 394, 433, 593], [2, 163, 728], [2, 164, 745, 777], [17, 58, 916], [15, 58, 850, 916], [15, 850, 935], [16, 173, 235, 883], [16, 258, 303, 528, 885], [16, 324, 420, 887], [16, 475, 528, 889], [16, 474, 497, 528, 889], [16, 477, 593, 889], [16, 542, 639, 890], [16, 478, 697, 889], [16, 479, 715, 889], [16, 323, 394, 443, 887], [16, 546, 728, 890], [16, 542, 633, 728, 890], [16, 478, 692, 728, 889], [16, 476, 545, 697, 889], [16, 476, 545, 692, 728, 889], [16, 652, 697, 892], [16, 482, 817, 889], [16, 654, 817, 892], [16, 481, 792, 817, 889], [16, 484, 881, 889], [16, 894, 915], [8, 653, 793, 830, 935], [16, 74, 479, 698, 889], [16, 103, 464, 889], [16, 486, 889, 935], [16, 103, 481, 780, 889], [16, 74, 894, 895], [16, 146, 894, 897], [16, 48, 186, 831, 893, 936], [16, 107, 186, 894, 896], [16, 235, 894, 900], [16, 830, 893, 935], [16, 20, 235, 818, 893], [16, 186, 830, 893, 918], [16, 894, 914, 935], [16, 109, 235, 894, 896], [16, 186, 894, 914, 918], [16, 45, 107, 186, 831, 893, 936], [16, 45, 109, 235, 831, 893, 936], [16, 130, 235, 894, 897], [2, 74, 164, 729], [16, 74, 831, 893, 937], [16, 46, 146, 831, 893, 936], [16, 46, 130, 235, 831, 893, 936], [16, 545, 697, 890], [16, 480, 765, 795, 881, 889], [16, 654, 815, 892, 915], [16, 480, 765, 792, 817, 889], [16, 74, 654, 799, 892], [16, 485, 889, 915], [16, 74, 480, 752, 889], [16, 74, 485, 889, 895], [16, 479, 712, 792, 817, 889], [16, 653, 795, 881, 892], [16, 146, 654, 815, 892, 897], [16, 186, 655, 832, 892], [16, 146, 480, 753, 889], [16, 186, 465, 889], [16, 186, 486, 889, 918], [2, 103, 164, 730], [2, 156, 477, 593], [2, 155, 432, 563, 593], [2, 154, 394, 432, 563, 593], [2, 154, 400, 728], [2, 154, 403, 777], [2, 155, 439, 817], [2, 154, 394, 439, 817], [2, 166, 881], [2, 154, 405, 915], [2, 156, 486, 935], [2, 74, 158, 529], [2, 61, 148, 239, 355], [2, 103, 156, 464], [2, 103, 161, 620], [2, 103, 158, 542, 620], [2, 103, 154, 398, 657], [3, 18, 107, 186, 294], [3, 20, 235, 294], [2, 146, 164, 746, 781], [2, 74, 154, 398, 656], [2, 18, 107, 164, 186, 746, 778], [3, 20, 235, 306, 746, 778], [3, 186, 310, 850, 918], [3, 20, 235, 309, 818], [11, 745, 777], [15, 44, 74, 850, 916], [9, 669, 745, 777], [3, 299, 372], [17, 48, 186, 916], [6, 387, 935], [6, 186, 387, 918], [11, 45, 107, 186, 745, 776, 830, 916], [3, 45, 107, 186, 295], [6, 109, 235, 374], [13, 103, 793, 829, 882], [13, 293, 793, 829, 886], [13, 132, 293, 781], [13, 355, 793, 829, 888], [13, 48, 186, 779], [13, 18, 107, 186, 778], [13, 23, 355, 778], [13, 45, 113, 355, 779], [13, 18, 113, 355, 778], [13, 20, 221, 355, 778], [13, 21, 239, 355, 778], [14, 153, 293, 819], [9, 77, 109, 235, 657], [6, 45, 109, 235, 387, 916], [6, 77, 107, 186, 373], [6, 77, 109, 235, 373], [11, 74, 729], [6, 74, 384, 729], [11, 103, 730], [6, 103, 384, 730], [3, 299, 369, 796], [16, 235, 485, 889, 900], [16, 20, 235, 483, 818, 889], [16, 109, 235, 485, 889, 896], [16, 45, 109, 235, 480, 751, 889], [16, 45, 109, 235, 486, 889, 916], [16, 293, 466, 889], [3, 45, 109, 235, 295], [3, 77, 107, 186, 296], [3, 77, 109, 235, 296], [3, 130, 235, 297], [13, 58, 779], [9, 103, 672, 882], [9, 257, 293, 658], [9, 61, 239, 355, 656], [9, 420, 662], [9, 443, 663], [16, 653, 796, 892], [11, 745, 774, 796], [17, 293, 922], [14, 363, 563, 593, 820], [12, 776, 830, 935], [1, 114, 369, 796], [2, 162, 652, 694, 777], [8, 58, 653, 779], [3, 306, 745, 774, 796], [15, 173, 235, 832], [1, 122, 694, 777]]\n",
    "\n",
    "# println(length(M_pos))\n",
    "# println(length(y))\n",
    "# println(length(P_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta = 0\n"
     ]
    }
   ],
   "source": [
    "theta = 0\n",
    "\n",
    "numPaths = length(P_pos)\n",
    "numY = length(M_pos)\n",
    "for i = 1:numPaths\n",
    "    path = P_pos[i]\n",
    "    theta_P = 0\n",
    "#     println(i, \"Path \", path)\n",
    "    for m = 1:numY\n",
    "        M = M_pos[m]\n",
    "#         println(\"\\tM = \", M)\n",
    "        M_P = intersect(M, path) \n",
    "        if length(M_P) > 0\n",
    "            q_MP = prod((1-q[a]) for a in M_P)\n",
    "        else\n",
    "            q_MP = 1\n",
    "        end\n",
    "        theta_P = theta_P + q_MP*y[m]\n",
    "    end\n",
    "    if theta < theta_P\n",
    "        theta = theta_P\n",
    "    end\n",
    "#     println(\"\\ttheta_P = \", theta_P)\n",
    "end\n",
    "println(\"theta = \", theta)\n",
    "timesFile = open(\"./TestInstances/theta_\"*dataSet*prob*\".txt\", \"a\")\n",
    "println(timesFile, dataSet*prob, \"; Ins \", ins, \"; theta \", theta)\n",
    "close(timesFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length(P_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_pos = Array{Int64,1}[[7], [3, 52, 64, 68, 109, 190], [5, 90, 154, 190], [1, 37, 48, 90, 190], [2, 41, 59, 76, 128, 190, 193, 204], [2, 42, 59, 90, 131, 190, 204], [1, 50, 76, 136, 190, 193], [5, 76, 116, 128, 155, 190, 193], [2, 51, 59, 76, 173, 190, 205, 226], [1, 50, 64, 122, 135, 190], [5, 41, 64, 122, 152, 190], [2, 59, 64, 167, 190, 208], [6, 42, 56, 76, 130, 159, 190, 193], [3, 20, 76, 110, 162, 190, 210, 231], [4, 76, 136, 190, 193], [4, 90, 123, 135, 190], [5, 56, 76, 130, 156, 190, 193], [2, 59, 76, 190, 193, 209, 222], [4, 43, 76, 133, 190, 193, 222], [3, 30, 64, 67, 92, 109, 167, 190], [3, 34, 67, 76, 109, 173, 190], [4, 41, 64, 122, 133, 190], [4, 42, 90, 131, 133, 190], [6, 26, 76, 158, 173, 190, 226], [3, 26, 76, 110, 158, 173, 190, 226], [3, 41, 76, 110, 128, 159, 190, 193], [3, 76, 110, 162, 173, 190, 214, 226], [1, 51, 76, 173, 190, 226], [4, 12, 76, 119, 135, 173, 190, 226], [5, 41, 76, 128, 152, 190, 193], [2, 11, 58, 64, 81, 167, 190], [5, 20, 76, 150, 190, 231], [2, 8, 14, 58, 76, 81, 184, 190, 193, 209, 222], [2, 8, 14, 58, 76, 81, 173, 184, 190, 209, 223, 238], [4, 64, 122, 135, 190], [6, 41, 64, 122, 159, 190], [3, 42, 52, 64, 110, 130, 159, 190], [3, 29, 56, 76, 110, 163, 190, 193, 229], [2, 41, 59, 64, 122, 190, 204], [6, 76, 145, 162, 190, 193, 213], [3, 76, 110, 145, 162, 190, 193, 213], [3, 56, 68, 76, 109, 190, 193], [1, 51, 76, 145, 190, 193, 225], [4, 25, 76, 120, 135, 190, 193, 222], [3, 41, 90, 110, 123, 159, 190], [2, 10, 58, 81, 90, 154, 190], [4, 20, 35, 76, 136, 190, 191, 231], [4, 76, 137, 173, 190, 217, 238], [1, 50, 76, 128, 135, 190, 193], [4, 37, 90, 137, 190, 215], [4, 64, 92, 137, 167, 190, 216], [4, 90, 131, 137, 190, 217, 237], [2, 16, 46, 58, 82, 90, 190, 210], [3, 52, 62, 68, 90, 109, 131, 190], [5, 16, 90, 150, 190], [4, 37, 76, 88, 98, 115, 136, 173, 190, 191, 223, 238], [3, 41, 64, 110, 122, 159, 190], [4, 26, 76, 120, 135, 173, 190, 226], [6, 41, 76, 128, 159, 190, 193], [2, 43, 59, 76, 173, 190, 204, 223, 238], [3, 32, 67, 76, 109, 148, 190, 231], [2, 45, 58, 64, 82, 122, 190, 196], [6, 42, 90, 131, 159, 190], [1, 39, 48, 64, 122, 190], [5, 17, 56, 76, 130, 150, 190, 193], [5, 76, 118, 155, 173, 190], [4, 76, 128, 135, 190, 193], [4, 42, 56, 76, 130, 133, 190, 193], [1, 20, 35, 48, 76, 190, 231], [2, 20, 59, 76, 96, 190, 207, 231], [3, 64, 71, 109, 122, 190, 196], [2, 20, 46, 58, 76, 82, 190, 210, 231], [5, 27, 29, 56, 76, 151, 190, 193, 229], [4, 25, 41, 76, 120, 133, 190, 193, 222], [5, 18, 76, 145, 150, 190, 193], [6, 26, 76, 145, 158, 190, 193, 225], [3, 26, 76, 110, 145, 158, 190, 193, 225], [1, 18, 35, 48, 76, 145, 190, 193], [6, 18, 76, 145, 162, 190, 193, 210], [3, 18, 76, 110, 145, 162, 190, 193, 210], [2, 12, 58, 76, 81, 173, 190, 226], [6, 16, 90, 162, 190, 210], [3, 72, 76, 109, 173, 190, 238], [2, 10, 20, 58, 76, 81, 150, 190, 231], [2, 20, 45, 58, 76, 82, 125, 150, 190, 196, 231], [6, 20, 76, 162, 190, 210, 231], [2, 46, 58, 76, 82, 173, 190, 214, 226], [3, 37, 41, 90, 110, 128, 159, 190, 191], [4, 37, 90, 128, 135, 190, 191], [3, 8, 14, 37, 70, 81, 90, 109, 179, 190], [4, 37, 90, 136, 190, 191], [3, 37, 55, 68, 90, 109, 179, 190], [3, 90, 110, 143, 162, 190, 213], [4, 20, 76, 125, 135, 150, 190, 231], [4, 16, 90, 125, 135, 150, 190], [4, 16, 40, 46, 90, 133, 190, 210], [6, 90, 143, 162, 190, 213], [6, 76, 162, 173, 190, 214, 226], [4, 37, 42, 56, 90, 130, 133, 190, 191]]\n",
    "length(P_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_u = unique(P_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.5",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
